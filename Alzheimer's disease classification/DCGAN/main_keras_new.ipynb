{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0b92622b2fb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataDir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/trojan/Desktop/dimentia/DCGAN/dataset/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m dataset = keras.preprocessing.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdataDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "dataDir = \"/home/trojan/Desktop/dimentia/DCGAN/dataset/\"\n",
    "\n",
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    dataDir, label_mode=None, image_size=(64, 64), batch_size=8\n",
    ")\n",
    "dataset = dataset.map(lambda x: x / 255.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in dataset:\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        3136      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 404,801\n",
      "Trainable params: 404,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(64, 64, 3)),\n",
    "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8192)              1056768   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 16, 16, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 3)         38403     \n",
      "=================================================================\n",
      "Total params: 3,979,651\n",
      "Trainable params: 3,979,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        layers.Dense(8 * 8 * 128),\n",
    "        layers.Reshape((8, 8, 128)),\n",
    "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(\"generated_images/generated_img_%03d_%d.png\" % (epoch, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "615/615 [==============================] - 62s 101ms/step - d_loss: 0.5757 - g_loss: 6.9483\n",
      "Epoch 2/100\n",
      "615/615 [==============================] - 62s 100ms/step - d_loss: 0.4748 - g_loss: 2.1220\n",
      "Epoch 3/100\n",
      "615/615 [==============================] - 59s 95ms/step - d_loss: 0.5081 - g_loss: 1.5749\n",
      "Epoch 4/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4845 - g_loss: 2.0578\n",
      "Epoch 5/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.3933 - g_loss: 2.2625\n",
      "Epoch 6/100\n",
      "615/615 [==============================] - 58s 95ms/step - d_loss: 0.4503 - g_loss: 2.1775\n",
      "Epoch 7/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4448 - g_loss: 2.4267\n",
      "Epoch 8/100\n",
      "615/615 [==============================] - 58s 95ms/step - d_loss: 0.4406 - g_loss: 1.5716\n",
      "Epoch 9/100\n",
      "615/615 [==============================] - 58s 95ms/step - d_loss: 0.4108 - g_loss: 1.8283\n",
      "Epoch 10/100\n",
      "615/615 [==============================] - 58s 95ms/step - d_loss: 0.3117 - g_loss: 2.1359\n",
      "Epoch 11/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.3243 - g_loss: 1.9540\n",
      "Epoch 12/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4261 - g_loss: 1.6331\n",
      "Epoch 13/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4998 - g_loss: 1.3838\n",
      "Epoch 14/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.5264 - g_loss: 1.3372\n",
      "Epoch 15/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.5284 - g_loss: 1.3066\n",
      "Epoch 16/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.5348 - g_loss: 1.2104\n",
      "Epoch 17/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.5431 - g_loss: 1.2338\n",
      "Epoch 18/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.5552 - g_loss: 1.2630\n",
      "Epoch 19/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.5368 - g_loss: 1.2246\n",
      "Epoch 20/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.5449 - g_loss: 1.2589\n",
      "Epoch 21/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.5415 - g_loss: 1.2414\n",
      "Epoch 22/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.5150 - g_loss: 1.2830\n",
      "Epoch 23/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4994 - g_loss: 1.3606\n",
      "Epoch 24/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4998 - g_loss: 1.3584\n",
      "Epoch 25/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.5008 - g_loss: 1.3392\n",
      "Epoch 26/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4977 - g_loss: 1.3582\n",
      "Epoch 27/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4852 - g_loss: 1.3578\n",
      "Epoch 28/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4828 - g_loss: 1.3984\n",
      "Epoch 29/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4777 - g_loss: 1.4508\n",
      "Epoch 30/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4801 - g_loss: 1.4161\n",
      "Epoch 31/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4743 - g_loss: 1.4408\n",
      "Epoch 32/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4759 - g_loss: 1.4629\n",
      "Epoch 33/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4714 - g_loss: 1.4700\n",
      "Epoch 34/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4748 - g_loss: 1.4471\n",
      "Epoch 35/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4692 - g_loss: 1.5294\n",
      "Epoch 36/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4584 - g_loss: 1.5493\n",
      "Epoch 37/100\n",
      "615/615 [==============================] - 58s 95ms/step - d_loss: 0.4521 - g_loss: 1.4896\n",
      "Epoch 38/100\n",
      "615/615 [==============================] - 58s 95ms/step - d_loss: 0.4452 - g_loss: 1.6144\n",
      "Epoch 39/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4712 - g_loss: 1.5020\n",
      "Epoch 40/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4454 - g_loss: 1.5656\n",
      "Epoch 41/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4551 - g_loss: 1.5781\n",
      "Epoch 42/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4625 - g_loss: 1.5109\n",
      "Epoch 43/100\n",
      "615/615 [==============================] - 58s 95ms/step - d_loss: 0.4578 - g_loss: 1.5640\n",
      "Epoch 44/100\n",
      "615/615 [==============================] - 58s 95ms/step - d_loss: 0.4695 - g_loss: 1.5541\n",
      "Epoch 45/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4389 - g_loss: 1.6586\n",
      "Epoch 46/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4479 - g_loss: 1.5846\n",
      "Epoch 47/100\n",
      "615/615 [==============================] - 58s 95ms/step - d_loss: 0.4559 - g_loss: 1.5916\n",
      "Epoch 48/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4631 - g_loss: 1.5757\n",
      "Epoch 49/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4538 - g_loss: 1.5790\n",
      "Epoch 50/100\n",
      "615/615 [==============================] - 58s 95ms/step - d_loss: 0.4432 - g_loss: 1.5882\n",
      "Epoch 51/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4319 - g_loss: 1.6793\n",
      "Epoch 52/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4287 - g_loss: 1.6632\n",
      "Epoch 53/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4474 - g_loss: 1.6014\n",
      "Epoch 54/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4386 - g_loss: 1.6399\n",
      "Epoch 55/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4354 - g_loss: 1.6297\n",
      "Epoch 56/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4475 - g_loss: 1.5975\n",
      "Epoch 57/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4194 - g_loss: 1.6850\n",
      "Epoch 58/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4360 - g_loss: 1.6869\n",
      "Epoch 59/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4209 - g_loss: 1.6544\n",
      "Epoch 60/100\n",
      "615/615 [==============================] - 58s 95ms/step - d_loss: 0.4371 - g_loss: 1.6651\n",
      "Epoch 61/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4365 - g_loss: 1.7021\n",
      "Epoch 62/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4256 - g_loss: 1.6426\n",
      "Epoch 63/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4312 - g_loss: 1.6592\n",
      "Epoch 64/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4293 - g_loss: 1.6861\n",
      "Epoch 65/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4385 - g_loss: 1.6907\n",
      "Epoch 66/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4438 - g_loss: 1.6469\n",
      "Epoch 67/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4269 - g_loss: 1.6730\n",
      "Epoch 68/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4387 - g_loss: 1.6537\n",
      "Epoch 69/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4419 - g_loss: 1.6955\n",
      "Epoch 70/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4554 - g_loss: 1.6369\n",
      "Epoch 71/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4359 - g_loss: 1.6154\n",
      "Epoch 72/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4455 - g_loss: 1.6738\n",
      "Epoch 73/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4469 - g_loss: 1.6678\n",
      "Epoch 74/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4522 - g_loss: 1.6354\n",
      "Epoch 75/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4506 - g_loss: 1.6437\n",
      "Epoch 76/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4373 - g_loss: 1.6286\n",
      "Epoch 77/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4570 - g_loss: 1.6229\n",
      "Epoch 78/100\n",
      "615/615 [==============================] - 58s 94ms/step - d_loss: 0.4571 - g_loss: 1.6459\n",
      "Epoch 79/100\n",
      "615/615 [==============================] - 62s 101ms/step - d_loss: 0.4568 - g_loss: 1.5986\n",
      "Epoch 80/100\n",
      "615/615 [==============================] - 62s 101ms/step - d_loss: 0.4654 - g_loss: 1.6055\n",
      "Epoch 81/100\n",
      "615/615 [==============================] - 62s 100ms/step - d_loss: 0.4404 - g_loss: 1.6183\n",
      "Epoch 82/100\n",
      "615/615 [==============================] - 61s 100ms/step - d_loss: 0.4488 - g_loss: 1.6575\n",
      "Epoch 83/100\n",
      "615/615 [==============================] - 62s 100ms/step - d_loss: 0.4724 - g_loss: 1.6343\n",
      "Epoch 84/100\n",
      "615/615 [==============================] - 62s 101ms/step - d_loss: 0.4719 - g_loss: 1.5940\n",
      "Epoch 85/100\n",
      "615/615 [==============================] - 62s 100ms/step - d_loss: 0.4625 - g_loss: 1.6045\n",
      "Epoch 86/100\n",
      "615/615 [==============================] - 62s 101ms/step - d_loss: 0.4662 - g_loss: 1.6012\n",
      "Epoch 87/100\n",
      "615/615 [==============================] - 62s 101ms/step - d_loss: 0.4691 - g_loss: 1.6066\n",
      "Epoch 88/100\n",
      "615/615 [==============================] - 62s 101ms/step - d_loss: 0.4552 - g_loss: 1.6030\n",
      "Epoch 89/100\n",
      "615/615 [==============================] - 62s 101ms/step - d_loss: 0.4585 - g_loss: 1.5858\n",
      "Epoch 90/100\n",
      "615/615 [==============================] - 62s 100ms/step - d_loss: 0.4589 - g_loss: 1.6157\n",
      "Epoch 91/100\n",
      "615/615 [==============================] - 62s 100ms/step - d_loss: 0.4599 - g_loss: 1.5862\n",
      "Epoch 92/100\n",
      "615/615 [==============================] - 62s 100ms/step - d_loss: 0.4756 - g_loss: 1.6221\n",
      "Epoch 93/100\n",
      "615/615 [==============================] - 62s 101ms/step - d_loss: 0.4672 - g_loss: 1.5390\n",
      "Epoch 94/100\n",
      "615/615 [==============================] - 62s 100ms/step - d_loss: 0.4540 - g_loss: 1.6325\n",
      "Epoch 95/100\n",
      "615/615 [==============================] - 62s 101ms/step - d_loss: 0.4609 - g_loss: 1.6029\n",
      "Epoch 96/100\n",
      "615/615 [==============================] - 62s 101ms/step - d_loss: 0.4871 - g_loss: 1.6115\n",
      "Epoch 97/100\n",
      "615/615 [==============================] - 62s 101ms/step - d_loss: 0.4873 - g_loss: 1.5419\n",
      "Epoch 98/100\n",
      "615/615 [==============================] - 62s 101ms/step - d_loss: 0.4745 - g_loss: 1.5258\n",
      "Epoch 99/100\n",
      "615/615 [==============================] - 61s 100ms/step - d_loss: 0.4596 - g_loss: 1.5941\n",
      "Epoch 100/100\n",
      "615/615 [==============================] - 62s 101ms/step - d_loss: 0.4764 - g_loss: 1.5840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fba341a9780>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100  # In practice, use ~100 epochs\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
