{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Concatenate\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from siamese import SiameseNetwork\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_classes = 2\n",
    "epochs = 50\n",
    "\n",
    "# input image dimensions\n",
    "img_height, img_width = 256, 256\n",
    "img_rows, img_cols = 256, 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"/home/trojan/Desktop/dimentia/CNN_simple/kfold/X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"/home/trojan/Desktop/dimentia/CNN_simple/kfold/y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19677, 256, 256, 3)\n",
      "(19677,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                  shuffle=True, stratify=y, \n",
    "                                                  test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (15741, 256, 256, 3)\n",
      "15741 train samples\n",
      "3936 validation samples\n",
      "y_train shape: (15741,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_val.shape[0], 'validation samples')\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    }
   ],
   "source": [
    "#print(x_train[1].dtype)\n",
    "print(np.min(x_train[1]), np.max(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_val = x_val.reshape(x_val.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_val = x_val.reshape(x_val.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_model(input_shape):\n",
    "    model_input = Input(shape=input_shape)\n",
    "\n",
    "    encoder = tf.keras.applications.DenseNet121(weights=None, include_top=False)\n",
    "    encoder.trainable = True\n",
    "\n",
    "    embedding = encoder(model_input, training=True)\n",
    "    embedding = GlobalAveragePooling2D()(embedding)\n",
    "    \n",
    "    embedding = Flatten()(embedding)\n",
    "    embedding = Dense(128)(embedding)\n",
    "    embedding = BatchNormalization()(embedding)\n",
    "    embedding = Activation(activation='relu')(embedding)\n",
    "    \n",
    "    \n",
    "    return Model(model_input, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_head_model(embedding_shape):\n",
    "    embedding_a = Input(shape=128)\n",
    "    embedding_b = Input(shape=128)\n",
    "\n",
    "    head = Concatenate()([embedding_a, embedding_b])\n",
    "    head = Dense(8)(head)\n",
    "    head = BatchNormalization()(head)\n",
    "    head = Activation(activation='sigmoid')(head)\n",
    "\n",
    "    head = Dense(1)(head)\n",
    "    head = BatchNormalization()(head)\n",
    "    head = Activation(activation='sigmoid')(head)\n",
    "\n",
    "    return Model([embedding_a, embedding_b], head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "\n",
    "    lr = 1e-4 \n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 60: # 120\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 30: #80\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = create_base_model(input_shape)\n",
    "head_model = create_head_model(base_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0001\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "siamese_network = SiameseNetwork(base_model, head_model)\n",
    "siamese_network.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "                        optimizer=tf.keras.optimizers.Adam(lr=lr_schedule(0)),\n",
    "                        metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "siamese_checkpoint_path = \"./siamese_checkpoint\"\n",
    "filepath = siamese_checkpoint_path + '/' + 'siamese_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_callbacks = [\n",
    "    #EarlyStopping(monitor='val_accuracy', patience=10, verbose=0),\n",
    "    ModelCheckpoint(filepath, monitor='val_binary_accuracy', mode='max', save_best_only=True, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/trojan/Desktop/dimentia/Siamese network/siamese.py:75: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.7883 - binary_accuracy: 0.5004\n",
      "Epoch 00001: val_binary_accuracy improved from -inf to 0.49314, saving model to ./siamese_checkpoint/siamese_model.h5\n",
      "3936/3935 [==============================] - 543s 138ms/step - loss: 0.7883 - binary_accuracy: 0.5004 - val_loss: 0.7669 - val_binary_accuracy: 0.4931\n",
      "Epoch 2/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.7489 - binary_accuracy: 0.4983\n",
      "Epoch 00002: val_binary_accuracy improved from 0.49314 to 0.50965, saving model to ./siamese_checkpoint/siamese_model.h5\n",
      "3936/3935 [==============================] - 552s 140ms/step - loss: 0.7489 - binary_accuracy: 0.4983 - val_loss: 0.7394 - val_binary_accuracy: 0.5097\n",
      "Epoch 3/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.7252 - binary_accuracy: 0.4996\n",
      "Epoch 00003: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 561s 143ms/step - loss: 0.7252 - binary_accuracy: 0.4996 - val_loss: 0.7128 - val_binary_accuracy: 0.5066\n",
      "Epoch 4/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.7104 - binary_accuracy: 0.4977\n",
      "Epoch 00004: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 566s 144ms/step - loss: 0.7104 - binary_accuracy: 0.4977 - val_loss: 0.7045 - val_binary_accuracy: 0.4921\n",
      "Epoch 5/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.7050 - binary_accuracy: 0.4940\n",
      "Epoch 00005: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 566s 144ms/step - loss: 0.7050 - binary_accuracy: 0.4940 - val_loss: 0.6998 - val_binary_accuracy: 0.5015\n",
      "Epoch 6/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6970 - binary_accuracy: 0.5046\n",
      "Epoch 00006: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 565s 144ms/step - loss: 0.6970 - binary_accuracy: 0.5046 - val_loss: 0.6976 - val_binary_accuracy: 0.4952\n",
      "Epoch 7/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6960 - binary_accuracy: 0.4954\n",
      "Epoch 00007: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 566s 144ms/step - loss: 0.6960 - binary_accuracy: 0.4954 - val_loss: 0.6951 - val_binary_accuracy: 0.4888\n",
      "Epoch 8/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6948 - binary_accuracy: 0.4923\n",
      "Epoch 00008: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 565s 144ms/step - loss: 0.6948 - binary_accuracy: 0.4923 - val_loss: 0.6938 - val_binary_accuracy: 0.4970\n",
      "Epoch 9/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6937 - binary_accuracy: 0.4971\n",
      "Epoch 00009: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 565s 144ms/step - loss: 0.6937 - binary_accuracy: 0.4971 - val_loss: 0.6931 - val_binary_accuracy: 0.5018\n",
      "Epoch 10/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6935 - binary_accuracy: 0.4972\n",
      "Epoch 00010: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 565s 144ms/step - loss: 0.6935 - binary_accuracy: 0.4972 - val_loss: 0.6933 - val_binary_accuracy: 0.4942\n",
      "Epoch 11/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6934 - binary_accuracy: 0.4954\n",
      "Epoch 00011: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 565s 144ms/step - loss: 0.6934 - binary_accuracy: 0.4954 - val_loss: 0.6930 - val_binary_accuracy: 0.5086\n",
      "Epoch 12/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4891\n",
      "Epoch 00012: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 565s 144ms/step - loss: 0.6932 - binary_accuracy: 0.4891 - val_loss: 0.6932 - val_binary_accuracy: 0.4959\n",
      "Epoch 13/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.4998\n",
      "Epoch 00013: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 565s 144ms/step - loss: 0.6931 - binary_accuracy: 0.4998 - val_loss: 0.6932 - val_binary_accuracy: 0.5020\n",
      "Epoch 14/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4966\n",
      "Epoch 00014: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 565s 144ms/step - loss: 0.6932 - binary_accuracy: 0.4966 - val_loss: 0.6931 - val_binary_accuracy: 0.4995\n",
      "Epoch 15/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5001\n",
      "Epoch 00015: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 565s 144ms/step - loss: 0.6932 - binary_accuracy: 0.5001 - val_loss: 0.6931 - val_binary_accuracy: 0.5030\n",
      "Epoch 16/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4945\n",
      "Epoch 00016: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 565s 144ms/step - loss: 0.6932 - binary_accuracy: 0.4945 - val_loss: 0.6932 - val_binary_accuracy: 0.4832\n",
      "Epoch 17/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4991\n",
      "Epoch 00017: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 565s 144ms/step - loss: 0.6932 - binary_accuracy: 0.4991 - val_loss: 0.6932 - val_binary_accuracy: 0.4962\n",
      "Epoch 18/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.4917\n",
      "Epoch 00018: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 565s 143ms/step - loss: 0.6932 - binary_accuracy: 0.4917 - val_loss: 0.6931 - val_binary_accuracy: 0.5053\n",
      "Epoch 19/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6932 - binary_accuracy: 0.5028\n",
      "Epoch 00019: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 565s 143ms/step - loss: 0.6932 - binary_accuracy: 0.5028 - val_loss: 0.6931 - val_binary_accuracy: 0.5069\n",
      "Epoch 20/50\n",
      "3936/3935 [==============================] - ETA: 0s - loss: 0.6931 - binary_accuracy: 0.4994\n",
      "Epoch 00020: val_binary_accuracy did not improve from 0.50965\n",
      "3936/3935 [==============================] - 564s 143ms/step - loss: 0.6931 - binary_accuracy: 0.4994 - val_loss: 0.6932 - val_binary_accuracy: 0.4954\n",
      "Epoch 21/50\n",
      " 705/3935 [====>.........................] - ETA: 7:07 - loss: 0.6932 - binary_accuracy: 0.4855"
     ]
    }
   ],
   "source": [
    "siamese_network.fit(x_train, y_train,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    callbacks=siamese_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network.load_weights(filepath)\n",
    "embedding = base_model.outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add softmax layer to the pre-trained embedding network\n",
    "embedding = Dense(1)(embedding)\n",
    "embedding = BatchNormalization()(embedding)\n",
    "embedding = Activation(activation='sigmoid')(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(base_model.inputs[0], embedding)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "                        optimizer=tf.keras.optimizers.Adam(lr=lr_schedule(0)),\n",
    "                        metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "model_checkpoint_path = \"./model_checkpoint\"\n",
    "filepath = model_checkpoint_path + '/' + 'best_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model__callbacks = [\n",
    "    #EarlyStopping(monitor='val_accuracy', patience=10, verbose=0),\n",
    "    ModelCheckpoint(filepath, monitor='val_binary_accuracy', save_best_only=True, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=model__callbacks,\n",
    "          validation_data=(x_val, y_val)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath)\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Val loss:', score[0])\n",
    "print('Val accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
