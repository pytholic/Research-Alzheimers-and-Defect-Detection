{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.layers import Multiply\n",
    "from tensorflow.keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(input, input_channels=None, output_channels=None, kernel_size=(3, 3), stride=1):\n",
    "    \"\"\"\n",
    "    full pre-activation residual block\n",
    "    https://arxiv.org/pdf/1603.05027.pdf\n",
    "    \"\"\"\n",
    "    if output_channels is None:\n",
    "        output_channels = input.get_shape()[-1].value\n",
    "    if input_channels is None:\n",
    "        input_channels = output_channels // 4\n",
    "\n",
    "    strides = (stride, stride)\n",
    "\n",
    "    x = BatchNormalization()(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(input_channels, (1, 1))(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(input_channels, kernel_size, padding='same', strides=stride)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(output_channels, (1, 1), padding='same')(x)\n",
    "\n",
    "    if input_channels != output_channels or stride != 1:\n",
    "        input = Conv2D(output_channels, (1, 1), padding='same', strides=strides)(input)\n",
    "\n",
    "    x = Add()([x, input])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_block(input, input_channels=None, output_channels=None, encoder_depth=1):\n",
    "    \"\"\"\n",
    "    attention block\n",
    "    https://arxiv.org/abs/1704.06904\n",
    "    \"\"\"\n",
    "\n",
    "    p = 1\n",
    "    t = 2\n",
    "    r = 1\n",
    "\n",
    "    if input_channels is None:\n",
    "        input_channels = input.get_shape()[-1].value\n",
    "    if output_channels is None:\n",
    "        output_channels = input_channels\n",
    "\n",
    "    # First Residual Block\n",
    "    for i in range(p):\n",
    "        input = residual_block(input)\n",
    "\n",
    "    # Trunc Branch\n",
    "    output_trunk = input\n",
    "    for i in range(t):\n",
    "        output_trunk = residual_block(output_trunk)\n",
    "\n",
    "    # Soft Mask Branch\n",
    "\n",
    "    ## encoder\n",
    "    ### first down sampling\n",
    "    output_soft_mask = MaxPool2D(padding='same')(input)  # 32x32\n",
    "    for i in range(r):\n",
    "        output_soft_mask = residual_block(output_soft_mask)\n",
    "\n",
    "    skip_connections = []\n",
    "    for i in range(encoder_depth - 1):\n",
    "\n",
    "        ## skip connections\n",
    "        output_skip_connection = residual_block(output_soft_mask)\n",
    "        skip_connections.append(output_skip_connection)\n",
    "        # print ('skip shape:', output_skip_connection.get_shape())\n",
    "\n",
    "        ## down sampling\n",
    "        output_soft_mask = MaxPool2D(padding='same')(output_soft_mask)\n",
    "        for _ in range(r):\n",
    "            output_soft_mask = residual_block(output_soft_mask)\n",
    "\n",
    "            ## decoder\n",
    "    skip_connections = list(reversed(skip_connections))\n",
    "    for i in range(encoder_depth - 1):\n",
    "        ## upsampling\n",
    "        for _ in range(r):\n",
    "            output_soft_mask = residual_block(output_soft_mask)\n",
    "        output_soft_mask = UpSampling2D()(output_soft_mask)\n",
    "        ## skip connections\n",
    "        output_soft_mask = Add()([output_soft_mask, skip_connections[i]])\n",
    "\n",
    "    ### last upsampling\n",
    "    for i in range(r):\n",
    "        output_soft_mask = residual_block(output_soft_mask)\n",
    "    output_soft_mask = UpSampling2D()(output_soft_mask)\n",
    "\n",
    "    ## Output\n",
    "    output_soft_mask = Conv2D(input_channels, (1, 1))(output_soft_mask)\n",
    "    output_soft_mask = Conv2D(input_channels, (1, 1))(output_soft_mask)\n",
    "    output_soft_mask = Activation('sigmoid')(output_soft_mask)\n",
    "\n",
    "    # Attention: (1 + output_soft_mask) * output_trunk\n",
    "    output = Lambda(lambda x: x + 1)(output_soft_mask)\n",
    "    output = Multiply()([output, output_trunk])  #\n",
    "\n",
    "    # Last Residual Block\n",
    "    for i in range(p):\n",
    "        output = residual_block(output)\n",
    "\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
