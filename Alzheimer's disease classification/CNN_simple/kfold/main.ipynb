{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# more info on callbakcs: https://keras.io/callbacks/ model saver is cool too.\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19677, 256, 256, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19677,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "                         \n",
    "skf = StratifiedKFold(n_splits = 10, random_state = 7, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 32)      2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              33555456  \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                32800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              33792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 36,260,353\n",
      "Trainable params: 36,252,097\n",
      "Non-trainable params: 8,256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NAME = \"dimentia-simple-CNN-{}\".format(int(time.time()))\n",
    "initializer = 'he_normal'\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5, 5), padding='same', input_shape = (256, 256, 3), kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(1024, kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1024, kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(32, kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(32, kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1024, kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \n",
    "    lr = 1e-4 #1e-3\n",
    "    if epoch > 10: # 120\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0001\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "   1/2214 [..............................] - ETA: 1s - loss: 0.5662 - accuracy: 0.6250WARNING:tensorflow:From /home/trojan/.local/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/2214 [..............................] - ETA: 1:25 - loss: 0.5744 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0126s vs `on_train_batch_end` time: 0.0626s). Check your callbacks.\n",
      "2214/2214 [==============================] - 74s 33ms/step - loss: 0.5501 - accuracy: 0.7085\n",
      "Epoch 2/10\n",
      "2214/2214 [==============================] - 74s 33ms/step - loss: 0.3920 - accuracy: 0.8168\n",
      "Epoch 3/10\n",
      "2214/2214 [==============================] - 74s 33ms/step - loss: 0.3213 - accuracy: 0.8596\n",
      "Epoch 4/10\n",
      "2214/2214 [==============================] - 74s 33ms/step - loss: 0.2635 - accuracy: 0.8950\n",
      "Epoch 5/10\n",
      "2214/2214 [==============================] - 74s 33ms/step - loss: 0.2019 - accuracy: 0.9253\n",
      "Epoch 6/10\n",
      "2214/2214 [==============================] - 74s 33ms/step - loss: 0.1489 - accuracy: 0.9507\n",
      "Epoch 7/10\n",
      "2214/2214 [==============================] - 74s 33ms/step - loss: 0.1259 - accuracy: 0.9588\n",
      "Epoch 8/10\n",
      "2214/2214 [==============================] - 74s 33ms/step - loss: 0.1013 - accuracy: 0.9670\n",
      "Epoch 9/10\n",
      "2214/2214 [==============================] - 74s 33ms/step - loss: 0.0943 - accuracy: 0.9695\n",
      "Epoch 10/10\n",
      "2214/2214 [==============================] - 74s 33ms/step - loss: 0.0756 - accuracy: 0.97773s - loss: 0.0737 -  - ETA: 0s - loss: 0.0756 - accu\n",
      "62/62 [==============================] - 2s 35ms/step - loss: 0.2563 - accuracy: 0.8938\n",
      "Score for fold 1: loss of 0.25625553727149963; accuracy of 89.38007950782776%\n",
      "Learning rate:  0.0001\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/10\n",
      "   2/2214 [..............................] - ETA: 5:43 - loss: 0.2251 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0277s vs `on_train_batch_end` time: 0.2697s). Check your callbacks.\n",
      "2214/2214 [==============================] - 74s 34ms/step - loss: 0.0812 - accuracy: 0.9742\n",
      "Epoch 2/10\n",
      "2214/2214 [==============================] - 74s 33ms/step - loss: 0.0641 - accuracy: 0.9798\n",
      "Epoch 3/10\n",
      "2214/2214 [==============================] - 74s 33ms/step - loss: 0.0592 - accuracy: 0.98161s\n",
      "Epoch 4/10\n",
      "2214/2214 [==============================] - 74s 33ms/step - loss: 0.0621 - accuracy: 0.9814\n",
      "Epoch 5/10\n",
      "2214/2214 [==============================] - 74s 33ms/step - loss: 0.0496 - accuracy: 0.9848\n",
      "Epoch 6/10\n",
      "1995/2214 [==========================>...] - ETA: 7s - loss: 0.0581 - accuracy: 0.9818"
     ]
    }
   ],
   "source": [
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "for train, val in skf.split(X,y): # skf.split\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=\"/home/trojan/Desktop/dimentia/kfold/logs/{}\".format(NAME))\n",
    "    \n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    #es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
    "    filepath=\"model-fold_no{}.h5\".format(fold_no)\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='loss', mode='min', verbose=1, save_best_only=True)\n",
    "    #callbacks_list = checkpoint, es\n",
    "\n",
    "    #sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=Adam(lr=lr_schedule(0)),\n",
    "                  metrics=['accuracy'],\n",
    "                  )\n",
    "\n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    model.fit(X[train], y[train],\n",
    "              batch_size = 8,\n",
    "              verbose=1,\n",
    "              epochs=10,\n",
    "              callbacks=[tensorboard])\n",
    "    \n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(X[val], y[val], verbose=1)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    model.save(filepath)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
