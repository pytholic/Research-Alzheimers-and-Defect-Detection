{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# more info on callbakcs: https://keras.io/callbacks/ model saver is cool too.\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15743 images belonging to 2 classes.\n",
      "Found 3934 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=r\"/home/trojan/Desktop/dimentia/data_10slices/dataset with PGGAN/train\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=8,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "valid_generator = train_datagen.flow_from_directory(\n",
    "    directory=r\"/home/trojan/Desktop/dimentia/data_10slices/dataset with PGGAN/train\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=8,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 32)      2432      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      18496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              33555456  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                32800     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              33792     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1025      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 36,243,841\n",
      "Trainable params: 36,243,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NAME = \"dimentia-simple-CNN-{}\".format(int(time.time()))\n",
    "initializer = 'he_normal'\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5, 5)c, input_shape = (256, 256, 3), kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same', kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(1024, kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1024, kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(32, kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(32, kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1024, kernel_initializer=initializer))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \n",
    "    lr = 1e-4 #1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 50: # 120\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 30: #80\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0001\n"
     ]
    }
   ],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"/home/trojan/Desktop/dimentia/CNN_simple/logs/{}\".format(NAME))\n",
    "\n",
    "#es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=7)\n",
    "#filepath=\"weights-improvement-{epoch:02d}-{accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint('best_model_new_pggan.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'],\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-3f532db92663>:10: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/100\n",
      "   1/1967 [..............................] - ETA: 1s - loss: 2.0709 - accuracy: 0.5000WARNING:tensorflow:From /home/trojan/.local/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "   2/1967 [..............................] - ETA: 57s - loss: 1.9678 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0152s vs `on_train_batch_end` time: 0.0419s). Check your callbacks.\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.7118 - accuracy: 0.4866\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.49975, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 81s 41ms/step - loss: 0.7118 - accuracy: 0.4866 - val_loss: 0.6932 - val_accuracy: 0.4997\n",
      "Epoch 2/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5002\n",
      "Epoch 00002: val_accuracy improved from 0.49975 to 0.50025, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 78s 40ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.5003\n",
      "Epoch 3/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.6945 - accuracy: 0.4969\n",
      "Epoch 00003: val_accuracy did not improve from 0.50025\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.6945 - accuracy: 0.4969 - val_loss: 0.6931 - val_accuracy: 0.5003\n",
      "Epoch 4/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.4965\n",
      "Epoch 00004: val_accuracy improved from 0.50025 to 0.51757, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 79s 40ms/step - loss: 0.6935 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5176\n",
      "Epoch 5/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.4958\n",
      "Epoch 00005: val_accuracy did not improve from 0.51757\n",
      "1967/1967 [==============================] - 78s 39ms/step - loss: 0.6933 - accuracy: 0.4958 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.4949\n",
      "Epoch 00006: val_accuracy did not improve from 0.51757\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.6932 - accuracy: 0.4949 - val_loss: 0.6932 - val_accuracy: 0.5005\n",
      "Epoch 7/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5011\n",
      "Epoch 00007: val_accuracy did not improve from 0.51757\n",
      "1967/1967 [==============================] - 78s 39ms/step - loss: 0.6932 - accuracy: 0.5011 - val_loss: 0.6931 - val_accuracy: 0.4995\n",
      "Epoch 8/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.6471 - accuracy: 0.5901\n",
      "Epoch 00008: val_accuracy improved from 0.51757 to 0.81314, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 80s 41ms/step - loss: 0.6471 - accuracy: 0.5901 - val_loss: 0.4536 - val_accuracy: 0.8131\n",
      "Epoch 9/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.3768 - accuracy: 0.7961\n",
      "Epoch 00009: val_accuracy improved from 0.81314 to 0.85336, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 80s 41ms/step - loss: 0.3768 - accuracy: 0.7961 - val_loss: 0.2872 - val_accuracy: 0.8534\n",
      "Epoch 10/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.8374\n",
      "Epoch 00010: val_accuracy improved from 0.85336 to 0.88824, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 80s 41ms/step - loss: 0.3056 - accuracy: 0.8374 - val_loss: 0.2763 - val_accuracy: 0.8882\n",
      "Epoch 11/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.8686\n",
      "Epoch 00011: val_accuracy did not improve from 0.88824\n",
      "1967/1967 [==============================] - 79s 40ms/step - loss: 0.2632 - accuracy: 0.8686 - val_loss: 0.2654 - val_accuracy: 0.8806\n",
      "Epoch 12/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.8966\n",
      "Epoch 00012: val_accuracy did not improve from 0.88824\n",
      "1967/1967 [==============================] - 80s 41ms/step - loss: 0.2228 - accuracy: 0.8966 - val_loss: 0.2675 - val_accuracy: 0.8859\n",
      "Epoch 13/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.1840 - accuracy: 0.9209\n",
      "Epoch 00013: val_accuracy improved from 0.88824 to 0.91904, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 81s 41ms/step - loss: 0.1840 - accuracy: 0.9209 - val_loss: 0.2153 - val_accuracy: 0.9190\n",
      "Epoch 14/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.9381\n",
      "Epoch 00014: val_accuracy improved from 0.91904 to 0.92795, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 81s 41ms/step - loss: 0.1498 - accuracy: 0.9381 - val_loss: 0.1699 - val_accuracy: 0.9280\n",
      "Epoch 15/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.9516\n",
      "Epoch 00015: val_accuracy did not improve from 0.92795\n",
      "1967/1967 [==============================] - 80s 41ms/step - loss: 0.1173 - accuracy: 0.9516 - val_loss: 0.1833 - val_accuracy: 0.9229\n",
      "Epoch 16/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.9620\n",
      "Epoch 00016: val_accuracy improved from 0.92795 to 0.93228, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 82s 41ms/step - loss: 0.0967 - accuracy: 0.9620 - val_loss: 0.1575 - val_accuracy: 0.9323\n",
      "Epoch 17/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9690\n",
      "Epoch 00017: val_accuracy improved from 0.93228 to 0.94857, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 82s 41ms/step - loss: 0.0803 - accuracy: 0.9690 - val_loss: 0.1331 - val_accuracy: 0.9486\n",
      "Epoch 18/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9753\n",
      "Epoch 00018: val_accuracy did not improve from 0.94857\n",
      "1967/1967 [==============================] - 80s 41ms/step - loss: 0.0686 - accuracy: 0.9753 - val_loss: 0.1679 - val_accuracy: 0.9274\n",
      "Epoch 19/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9790\n",
      "Epoch 00019: val_accuracy improved from 0.94857 to 0.95163, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 82s 41ms/step - loss: 0.0580 - accuracy: 0.9790 - val_loss: 0.1225 - val_accuracy: 0.9516\n",
      "Epoch 20/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.9818\n",
      "Epoch 00020: val_accuracy did not improve from 0.95163\n",
      "1967/1967 [==============================] - 78s 40ms/step - loss: 0.0483 - accuracy: 0.9818 - val_loss: 0.1860 - val_accuracy: 0.9145\n",
      "Epoch 21/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9847\n",
      "Epoch 00021: val_accuracy improved from 0.95163 to 0.96029, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 80s 41ms/step - loss: 0.0442 - accuracy: 0.9847 - val_loss: 0.1064 - val_accuracy: 0.9603\n",
      "Epoch 22/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9867\n",
      "Epoch 00022: val_accuracy did not improve from 0.96029\n",
      "1967/1967 [==============================] - 78s 40ms/step - loss: 0.0424 - accuracy: 0.9867 - val_loss: 0.1392 - val_accuracy: 0.9516\n",
      "Epoch 23/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9854\n",
      "Epoch 00023: val_accuracy improved from 0.96029 to 0.96054, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 80s 41ms/step - loss: 0.0407 - accuracy: 0.9854 - val_loss: 0.1254 - val_accuracy: 0.9605\n",
      "Epoch 24/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9894\n",
      "Epoch 00024: val_accuracy did not improve from 0.96054\n",
      "1967/1967 [==============================] - 78s 39ms/step - loss: 0.0312 - accuracy: 0.9894 - val_loss: 0.1199 - val_accuracy: 0.9509\n",
      "Epoch 25/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9879\n",
      "Epoch 00025: val_accuracy did not improve from 0.96054\n",
      "1967/1967 [==============================] - 78s 39ms/step - loss: 0.0334 - accuracy: 0.9879 - val_loss: 0.1209 - val_accuracy: 0.9562\n",
      "Epoch 26/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9922\n",
      "Epoch 00026: val_accuracy did not improve from 0.96054\n",
      "1967/1967 [==============================] - 78s 39ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 0.1083 - val_accuracy: 0.9570\n",
      "Epoch 27/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9910\n",
      "Epoch 00027: val_accuracy improved from 0.96054 to 0.96385, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 79s 40ms/step - loss: 0.0273 - accuracy: 0.9910 - val_loss: 0.1061 - val_accuracy: 0.9638\n",
      "Epoch 28/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9924\n",
      "Epoch 00028: val_accuracy did not improve from 0.96385\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0261 - accuracy: 0.9924 - val_loss: 0.1003 - val_accuracy: 0.9638\n",
      "Epoch 29/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9907\n",
      "Epoch 00029: val_accuracy did not improve from 0.96385\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0298 - accuracy: 0.9907 - val_loss: 0.1272 - val_accuracy: 0.9570\n",
      "Epoch 30/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9915\n",
      "Epoch 00030: val_accuracy improved from 0.96385 to 0.96640, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 79s 40ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.1187 - val_accuracy: 0.9664\n",
      "Epoch 31/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9926\n",
      "Epoch 00031: val_accuracy improved from 0.96640 to 0.96741, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 79s 40ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.0908 - val_accuracy: 0.9674\n",
      "Epoch 32/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9932\n",
      "Epoch 00032: val_accuracy did not improve from 0.96741\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.1228 - val_accuracy: 0.9519\n",
      "Epoch 33/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9922\n",
      "Epoch 00033: val_accuracy did not improve from 0.96741\n",
      "1967/1967 [==============================] - 78s 39ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.0941 - val_accuracy: 0.9636\n",
      "Epoch 34/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9940\n",
      "Epoch 00034: val_accuracy did not improve from 0.96741\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.1163 - val_accuracy: 0.9649\n",
      "Epoch 35/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9933\n",
      "Epoch 00035: val_accuracy improved from 0.96741 to 0.97301, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 79s 40ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.0815 - val_accuracy: 0.9730\n",
      "Epoch 36/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9953\n",
      "Epoch 00036: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.0984 - val_accuracy: 0.9644\n",
      "Epoch 37/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9941\n",
      "Epoch 00037: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.0822 - val_accuracy: 0.9723\n",
      "Epoch 38/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9927\n",
      "Epoch 00038: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.0960 - val_accuracy: 0.9672\n",
      "Epoch 39/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9933\n",
      "Epoch 00039: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0195 - accuracy: 0.9933 - val_loss: 0.0927 - val_accuracy: 0.9633\n",
      "Epoch 40/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9956\n",
      "Epoch 00040: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.1166 - val_accuracy: 0.9514\n",
      "Epoch 41/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9936\n",
      "Epoch 00041: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.1091 - val_accuracy: 0.9666\n",
      "Epoch 42/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9953\n",
      "Epoch 00042: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.1657 - val_accuracy: 0.9106\n",
      "Epoch 43/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9939\n",
      "Epoch 00043: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.1822 - val_accuracy: 0.9310\n",
      "Epoch 44/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9947\n",
      "Epoch 00044: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0177 - accuracy: 0.9947 - val_loss: 0.0912 - val_accuracy: 0.9651\n",
      "Epoch 45/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9938\n",
      "Epoch 00045: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0182 - accuracy: 0.9938 - val_loss: 0.1317 - val_accuracy: 0.9481\n",
      "Epoch 46/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9968\n",
      "Epoch 00046: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0730 - val_accuracy: 0.9710\n",
      "Epoch 47/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9948\n",
      "Epoch 00047: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.0853 - val_accuracy: 0.9674\n",
      "Epoch 48/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9959\n",
      "Epoch 00048: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0159 - accuracy: 0.9959 - val_loss: 0.0899 - val_accuracy: 0.9700\n",
      "Epoch 49/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9957\n",
      "Epoch 00049: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0162 - accuracy: 0.9957 - val_loss: 0.0895 - val_accuracy: 0.9651\n",
      "Epoch 50/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9961\n",
      "Epoch 00050: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.0935 - val_accuracy: 0.9679\n",
      "Epoch 51/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9968\n",
      "Epoch 00051: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.0918 - val_accuracy: 0.9684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9940\n",
      "Epoch 00052: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.1143 - val_accuracy: 0.9544\n",
      "Epoch 53/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9964\n",
      "Epoch 00053: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.1075 - val_accuracy: 0.9636\n",
      "Epoch 54/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9959\n",
      "Epoch 00054: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.0979 - val_accuracy: 0.9621\n",
      "Epoch 55/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9963\n",
      "Epoch 00055: val_accuracy did not improve from 0.97301\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.0797 - val_accuracy: 0.9659\n",
      "Epoch 56/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9962\n",
      "Epoch 00056: val_accuracy improved from 0.97301 to 0.97454, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 79s 40ms/step - loss: 0.0155 - accuracy: 0.9962 - val_loss: 0.0788 - val_accuracy: 0.9745\n",
      "Epoch 57/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9974\n",
      "Epoch 00057: val_accuracy improved from 0.97454 to 0.97658, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 79s 40ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0755 - val_accuracy: 0.9766\n",
      "Epoch 58/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9950\n",
      "Epoch 00058: val_accuracy improved from 0.97658 to 0.97760, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 79s 40ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.0696 - val_accuracy: 0.9776\n",
      "Epoch 59/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9959\n",
      "Epoch 00059: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0163 - accuracy: 0.9959 - val_loss: 0.0977 - val_accuracy: 0.9659\n",
      "Epoch 60/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9976\n",
      "Epoch 00060: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0894 - val_accuracy: 0.9682\n",
      "Epoch 61/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9954\n",
      "Epoch 00061: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.0820 - val_accuracy: 0.9748\n",
      "Epoch 62/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9958\n",
      "Epoch 00062: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0168 - accuracy: 0.9958 - val_loss: 0.0770 - val_accuracy: 0.9735\n",
      "Epoch 63/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9956\n",
      "Epoch 00063: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.1766 - val_accuracy: 0.9221\n",
      "Epoch 64/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9960\n",
      "Epoch 00064: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0148 - accuracy: 0.9960 - val_loss: 0.0633 - val_accuracy: 0.9761\n",
      "Epoch 65/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9957\n",
      "Epoch 00065: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.0981 - val_accuracy: 0.9626\n",
      "Epoch 66/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9959\n",
      "Epoch 00066: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 78s 39ms/step - loss: 0.0188 - accuracy: 0.9959 - val_loss: 0.1137 - val_accuracy: 0.9666\n",
      "Epoch 67/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 00067: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1082 - val_accuracy: 0.9649\n",
      "Epoch 68/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9963\n",
      "Epoch 00068: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.0881 - val_accuracy: 0.9661\n",
      "Epoch 69/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9978\n",
      "Epoch 00069: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.0846 - val_accuracy: 0.9745\n",
      "Epoch 70/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9973\n",
      "Epoch 00070: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.0844 - val_accuracy: 0.9720\n",
      "Epoch 71/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9966\n",
      "Epoch 00071: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.0765 - val_accuracy: 0.9733\n",
      "Epoch 72/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9974\n",
      "Epoch 00072: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0137 - accuracy: 0.9974 - val_loss: 0.0834 - val_accuracy: 0.9692\n",
      "Epoch 73/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9981\n",
      "Epoch 00073: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.1009 - val_accuracy: 0.9672\n",
      "Epoch 74/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9962\n",
      "Epoch 00074: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.1045 - val_accuracy: 0.9710\n",
      "Epoch 75/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9970\n",
      "Epoch 00075: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.1001 - val_accuracy: 0.9626\n",
      "Epoch 76/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9975\n",
      "Epoch 00076: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0115 - accuracy: 0.9975 - val_loss: 0.0712 - val_accuracy: 0.9766\n",
      "Epoch 77/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9969\n",
      "Epoch 00077: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 0.0890 - val_accuracy: 0.9669\n",
      "Epoch 78/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9980\n",
      "Epoch 00078: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.1458 - val_accuracy: 0.9547\n",
      "Epoch 79/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9966\n",
      "Epoch 00079: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.1710 - val_accuracy: 0.9430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9968\n",
      "Epoch 00080: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.0801 - val_accuracy: 0.9682\n",
      "Epoch 81/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9967\n",
      "Epoch 00081: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0144 - accuracy: 0.9967 - val_loss: 0.1119 - val_accuracy: 0.9537\n",
      "Epoch 82/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9978\n",
      "Epoch 00082: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0888 - val_accuracy: 0.9659\n",
      "Epoch 83/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9971\n",
      "Epoch 00083: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.0829 - val_accuracy: 0.9771\n",
      "Epoch 84/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9975\n",
      "Epoch 00084: val_accuracy did not improve from 0.97760\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 0.0913 - val_accuracy: 0.9654\n",
      "Epoch 85/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9958\n",
      "Epoch 00085: val_accuracy improved from 0.97760 to 0.97811, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 79s 40ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0629 - val_accuracy: 0.9781\n",
      "Epoch 86/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9975\n",
      "Epoch 00086: val_accuracy did not improve from 0.97811\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0153 - accuracy: 0.9975 - val_loss: 0.0845 - val_accuracy: 0.9700\n",
      "Epoch 87/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9973\n",
      "Epoch 00087: val_accuracy did not improve from 0.97811\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.0695 - val_accuracy: 0.9738\n",
      "Epoch 88/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9977\n",
      "Epoch 00088: val_accuracy did not improve from 0.97811\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.0733 - val_accuracy: 0.9779\n",
      "Epoch 89/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9982\n",
      "Epoch 00089: val_accuracy did not improve from 0.97811\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.1192 - val_accuracy: 0.9588\n",
      "Epoch 90/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9975\n",
      "Epoch 00090: val_accuracy did not improve from 0.97811\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0111 - accuracy: 0.9975 - val_loss: 0.1207 - val_accuracy: 0.9501\n",
      "Epoch 91/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9965\n",
      "Epoch 00091: val_accuracy improved from 0.97811 to 0.97989, saving model to best_model_new_pggan.h5\n",
      "1967/1967 [==============================] - 79s 40ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.0654 - val_accuracy: 0.9799\n",
      "Epoch 92/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9974\n",
      "Epoch 00092: val_accuracy did not improve from 0.97989\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.1010 - val_accuracy: 0.9603\n",
      "Epoch 93/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9972\n",
      "Epoch 00093: val_accuracy did not improve from 0.97989\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0130 - accuracy: 0.9972 - val_loss: 0.1130 - val_accuracy: 0.9565\n",
      "Epoch 94/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9980\n",
      "Epoch 00094: val_accuracy did not improve from 0.97989\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.0791 - val_accuracy: 0.9725\n",
      "Epoch 95/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9950\n",
      "Epoch 00095: val_accuracy did not improve from 0.97989\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0209 - accuracy: 0.9950 - val_loss: 0.0979 - val_accuracy: 0.9590\n",
      "Epoch 96/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9982\n",
      "Epoch 00096: val_accuracy did not improve from 0.97989\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0774 - val_accuracy: 0.9692\n",
      "Epoch 97/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9956\n",
      "Epoch 00097: val_accuracy did not improve from 0.97989\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0187 - accuracy: 0.9956 - val_loss: 0.1073 - val_accuracy: 0.9603\n",
      "Epoch 98/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9980\n",
      "Epoch 00098: val_accuracy did not improve from 0.97989\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1067 - val_accuracy: 0.9689\n",
      "Epoch 99/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9958\n",
      "Epoch 00099: val_accuracy did not improve from 0.97989\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.0717 - val_accuracy: 0.9756\n",
      "Epoch 100/100\n",
      "1967/1967 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9988\n",
      "Epoch 00100: val_accuracy did not improve from 0.97989\n",
      "1967/1967 [==============================] - 77s 39ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0953 - val_accuracy: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8a1815b080>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data = valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=100,\n",
    "                    callbacks=[checkpoint, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: best_model_pggan.h5/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-653340fb6a10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model_pggan.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: best_model_pggan.h5/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('best_model_new_pggan.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(generator=valid_generator,\n",
    "steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
