{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# more info on callbakcs: https://keras.io/callbacks/ model saver is cool too.\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1640, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1640,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "                         \n",
    "skf = StratifiedKFold(n_splits = 10, random_state = 7, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 17,934,401\n",
      "Trainable params: 17,934,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NAME = \"dimentia-simple-CNN-{}\".format(int(time.time()))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(VGG16(include_top=False, weights='imagenet', input_shape = (224,224,3)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/5\n",
      "  1/185 [..............................] - ETA: 0s - loss: 0.7251 - accuracy: 0.6250WARNING:tensorflow:From /home/trojan/.local/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/185 [..............................] - ETA: 14s - loss: 0.7863 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0437s vs `on_train_batch_end` time: 0.1134s). Check your callbacks.\n",
      "185/185 [==============================] - 26s 143ms/step - loss: 0.7098 - accuracy: 0.5169\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 26s 142ms/step - loss: 0.6954 - accuracy: 0.5149\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 26s 142ms/step - loss: 0.6948 - accuracy: 0.4905\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 26s 143ms/step - loss: 0.6938 - accuracy: 0.4966\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.6933 - accuracy: 0.5081\n",
      "6/6 [==============================] - 1s 85ms/step - loss: 0.6937 - accuracy: 0.4146\n",
      "Score for fold 1: loss of 0.6937023997306824; accuracy of 41.46341383457184%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/5\n",
      "  2/185 [..............................] - ETA: 24s - loss: 0.6933 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0488s vs `on_train_batch_end` time: 0.1209s). Check your callbacks.\n",
      "185/185 [==============================] - 27s 148ms/step - loss: 0.6938 - accuracy: 0.4749\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 27s 146ms/step - loss: 0.6934 - accuracy: 0.4986\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 27s 148ms/step - loss: 0.6930 - accuracy: 0.4919\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 27s 148ms/step - loss: 0.6928 - accuracy: 0.5068\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.6917 - accuracy: 0.5000\n",
      "Score for fold 2: loss of 0.6916659474372864; accuracy of 50.0%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/5\n",
      "  2/185 [..............................] - ETA: 23s - loss: 0.6989 - accuracy: 0.5000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0446s vs `on_train_batch_end` time: 0.1125s). Check your callbacks.\n",
      "185/185 [==============================] - 26s 143ms/step - loss: 0.6927 - accuracy: 0.5027\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 26s 139ms/step - loss: 0.6935 - accuracy: 0.5257\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 26s 142ms/step - loss: 0.6921 - accuracy: 0.5237\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 28s 149ms/step - loss: 0.6917 - accuracy: 0.5366\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 28s 149ms/step - loss: 0.6877 - accuracy: 0.5400\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 0.6908 - accuracy: 0.5610\n",
      "Score for fold 3: loss of 0.6907556056976318; accuracy of 56.09756112098694%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/5\n",
      "  2/185 [..............................] - ETA: 24s - loss: 0.6969 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0492s vs `on_train_batch_end` time: 0.1230s). Check your callbacks.\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.6784 - accuracy: 0.5711\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.6767 - accuracy: 0.5556\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.6598 - accuracy: 0.6057\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.6482 - accuracy: 0.6253\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.6151 - accuracy: 0.6606\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 0.7088 - accuracy: 0.6037\n",
      "Score for fold 4: loss of 0.7088098526000977; accuracy of 60.36585569381714%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/5\n",
      "  2/185 [..............................] - ETA: 25s - loss: 0.5516 - accuracy: 0.6875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0464s vs `on_train_batch_end` time: 0.1244s). Check your callbacks.\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.5668 - accuracy: 0.7039\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 28s 149ms/step - loss: 0.5440 - accuracy: 0.7188\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 28s 149ms/step - loss: 0.4678 - accuracy: 0.7873\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.3838 - accuracy: 0.8320\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.3530 - accuracy: 0.8455\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 0.5584 - accuracy: 0.7500\n",
      "Score for fold 5: loss of 0.5584264993667603; accuracy of 75.0%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/5\n",
      "  2/185 [..............................] - ETA: 24s - loss: 0.3098 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0482s vs `on_train_batch_end` time: 0.1242s). Check your callbacks.\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.3333 - accuracy: 0.8496\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.2900 - accuracy: 0.8855\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.2078 - accuracy: 0.9241\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.1678 - accuracy: 0.9377\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 28s 150ms/step - loss: 0.1461 - accuracy: 0.9404\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 0.1502 - accuracy: 0.9512\n",
      "Score for fold 6: loss of 0.15021176636219025; accuracy of 95.12194991111755%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/5\n",
      "  2/185 [..............................] - ETA: 27s - loss: 0.0105 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0630s vs `on_train_batch_end` time: 0.1330s). Check your callbacks.\n",
      "185/185 [==============================] - 27s 147ms/step - loss: 0.1331 - accuracy: 0.9526\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 27s 146ms/step - loss: 0.1214 - accuracy: 0.9573\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 27s 147ms/step - loss: 0.1220 - accuracy: 0.9533\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 27s 147ms/step - loss: 0.0825 - accuracy: 0.9695\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 27s 146ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 0.0331 - accuracy: 0.9878\n",
      "Score for fold 7: loss of 0.03313061222434044; accuracy of 98.78048896789551%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/5\n",
      "  2/185 [..............................] - ETA: 29s - loss: 2.0207e-04 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0607s vs `on_train_batch_end` time: 0.1604s). Check your callbacks.\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 0.0354 - accuracy: 0.9905\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 26s 142ms/step - loss: 0.0949 - accuracy: 0.9682\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 26s 138ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 26s 138ms/step - loss: 5.4758e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 26s 138ms/step - loss: 3.5228e-04 - accuracy: 1.0000\n",
      "6/6 [==============================] - 1s 84ms/step - loss: 0.0130 - accuracy: 0.9939\n",
      "Score for fold 8: loss of 0.013038786128163338; accuracy of 99.39024448394775%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Epoch 1/5\n",
      "  2/185 [..............................] - ETA: 24s - loss: 4.5112e-05 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0472s vs `on_train_batch_end` time: 0.1215s). Check your callbacks.\n",
      "185/185 [==============================] - 26s 143ms/step - loss: 0.0012 - accuracy: 0.9993\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 26s 143ms/step - loss: 5.2161e-04 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 27s 144ms/step - loss: 3.0569e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 27s 145ms/step - loss: 2.1171e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 27s 147ms/step - loss: 1.0939e-04 - accuracy: 1.0000\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 1.6754e-05 - accuracy: 1.0000\n",
      "Score for fold 9: loss of 1.6754214811953716e-05; accuracy of 100.0%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Epoch 1/5\n",
      "  2/185 [..............................] - ETA: 24s - loss: 7.3988e-06 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0478s vs `on_train_batch_end` time: 0.1240s). Check your callbacks.\n",
      "185/185 [==============================] - 27s 148ms/step - loss: 1.1655e-04 - accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "185/185 [==============================] - 27s 147ms/step - loss: 9.9744e-05 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "185/185 [==============================] - 27s 148ms/step - loss: 6.1370e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "185/185 [==============================] - 27s 146ms/step - loss: 5.5273e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "185/185 [==============================] - 27s 146ms/step - loss: 2.3256e-04 - accuracy: 1.0000\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 6.2148e-06 - accuracy: 1.0000\n",
      "Score for fold 10: loss of 6.214826953510055e-06; accuracy of 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "for train, val in kf.split(X,y): # skf.split\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=\"/home/trojan/Desktop/dimentia/kfold/logs/{}\".format(NAME))\n",
    "\n",
    "    #es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
    "    filepath=\"model-fold_no{}.h5\".format(fold_no)\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='loss', mode='min', verbose=1, save_best_only=True)\n",
    "    #callbacks_list = checkpoint, es\n",
    "\n",
    "    #sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'],\n",
    "                  )\n",
    "\n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    model.fit(X[train], y[train],\n",
    "              batch_size = 8,\n",
    "              verbose=1,\n",
    "              epochs=5,\n",
    "              callbacks=[tensorboard])\n",
    "    \n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(X[val], y[val], verbose=1)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    model.save(filepath)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.6937023997306824 - Accuracy: 41.46341383457184%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.6916659474372864 - Accuracy: 50.0%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.6907556056976318 - Accuracy: 56.09756112098694%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.7088098526000977 - Accuracy: 60.36585569381714%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.5584264993667603 - Accuracy: 75.0%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 0.15021176636219025 - Accuracy: 95.12194991111755%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 0.03313061222434044 - Accuracy: 98.78048896789551%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 8 - Loss: 0.013038786128163338 - Accuracy: 99.39024448394775%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 9 - Loss: 1.6754214811953716e-05 - Accuracy: 100.0%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 10 - Loss: 6.214826953510055e-06 - Accuracy: 100.0%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 77.62195140123367 (+- 22.511564239386725)\n",
      "> Loss: 0.3539764438588918\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
