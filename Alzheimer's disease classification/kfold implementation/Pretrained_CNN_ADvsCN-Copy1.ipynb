{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# more info on callbakcs: https://keras.io/callbacks/ model saver is cool too.\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1640, 224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1640,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5, shuffle=True)\n",
    "                         \n",
    "skf = StratifiedKFold(n_splits = 10, random_state = 7, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 17,934,401\n",
      "Trainable params: 17,934,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NAME = \"dimentia-simple-CNN-{}\".format(int(time.time()))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(VGG16(include_top=False, weights='imagenet', input_shape = (224,224,3)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "  1/164 [..............................] - ETA: 0s - loss: 0.5066 - accuracy: 0.7500WARNING:tensorflow:From /home/trojan/.local/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/164 [..............................] - ETA: 12s - loss: 0.6040 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0042s vs `on_train_batch_end` time: 0.1514s). Check your callbacks.\n",
      "164/164 [==============================] - 22s 137ms/step - loss: 0.7264 - accuracy: 0.5114\n",
      "11/11 [==============================] - 1s 98ms/step - loss: 0.6933 - accuracy: 0.4909\n",
      "Score for fold 1: loss of 0.6933218836784363; accuracy of 49.08536672592163%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "  2/164 [..............................] - ETA: 23s - loss: 0.7048 - accuracy: 0.3750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0046s vs `on_train_batch_end` time: 0.1593s). Check your callbacks.\n",
      "164/164 [==============================] - 23s 142ms/step - loss: 0.6947 - accuracy: 0.4863\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.6923 - accuracy: 0.5091\n",
      "Score for fold 2: loss of 0.6923009157180786; accuracy of 50.91463327407837%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "  2/164 [..............................] - ETA: 23s - loss: 0.6985 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0043s vs `on_train_batch_end` time: 0.1607s). Check your callbacks.\n",
      "164/164 [==============================] - 24s 146ms/step - loss: 0.6937 - accuracy: 0.4992\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.6924 - accuracy: 0.5213\n",
      "Score for fold 3: loss of 0.6923943758010864; accuracy of 52.13414430618286%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "  2/164 [..............................] - ETA: 23s - loss: 0.6983 - accuracy: 0.3750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0043s vs `on_train_batch_end` time: 0.1619s). Check your callbacks.\n",
      "164/164 [==============================] - 24s 147ms/step - loss: 0.6944 - accuracy: 0.5130\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.6918 - accuracy: 0.6128\n",
      "Score for fold 4: loss of 0.6917561888694763; accuracy of 61.28048896789551%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "  2/164 [..............................] - ETA: 23s - loss: 0.6842 - accuracy: 0.8125WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0043s vs `on_train_batch_end` time: 0.1634s). Check your callbacks.\n",
      "164/164 [==============================] - 24s 147ms/step - loss: 0.6930 - accuracy: 0.5282\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.6909 - accuracy: 0.5000\n",
      "Score for fold 5: loss of 0.69087815284729; accuracy of 50.0%\n"
     ]
    }
   ],
   "source": [
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "fold_no = 1\n",
    "\n",
    "for train, val in kf.split(X,y): # skf.split\n",
    "\n",
    "    tensorboard = TensorBoard(log_dir=\"/home/trojan/Desktop/dimentia/kfold/logs/{}\".format(NAME))\n",
    "\n",
    "    #es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
    "    filepath=\"model-fold_no{}.h5\".format(fold_no)\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='loss', mode='min', verbose=1, save_best_only=True)\n",
    "    #callbacks_list = checkpoint, es\n",
    "\n",
    "    #sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'],\n",
    "                  )\n",
    "\n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    model.fit(X[train], y[train],\n",
    "              batch_size = 8,\n",
    "              verbose=1,\n",
    "              epochs=1,\n",
    "              callbacks=[tensorboard])\n",
    "    \n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(X[val], y[val], verbose=1)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    model.save(filepath)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.6933218836784363 - Accuracy: 49.08536672592163%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.6923009157180786 - Accuracy: 50.91463327407837%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.6923943758010864 - Accuracy: 52.13414430618286%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.6917561888694763 - Accuracy: 61.28048896789551%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.69087815284729 - Accuracy: 50.0%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 52.682926654815674 (+- 4.415577745911071)\n",
      "> Loss: 0.6921303033828735\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
