{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchsummary in /home/trojan/.local/lib/python3.6/site-packages (1.5.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trojan/.local/lib/python3.6/site-packages/chainer/_environment_check.py:73: UserWarning: \n",
      "--------------------------------------------------------------------------------\n",
      "CuPy (cupy-cuda101) version 8.1.0 may not be compatible with this version of Chainer.\n",
      "Please consider installing the supported version by running:\n",
      "  $ pip install 'cupy-cuda101>=7.7.0,<8.0.0'\n",
      "\n",
      "See the following page for more details:\n",
      "  https://docs-cupy.chainer.org/en/latest/install.html\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  requirement=requirement, help=help))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import pdb\n",
    "from torch import nn\n",
    "import math\n",
    "from torch.optim import lr_scheduler\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from torch.nn import MaxPool2d\n",
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "import chainer.links as L\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if gpu is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/trojan/Desktop/dimentia/data_10slices/dataset with PGGAN/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                       transforms.Resize((28,28)),\n",
    "                       transforms.Grayscale(num_output_channels=1),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "                   ])\n",
    "dataset = torchvision.datasets.ImageFolder(root=data_path, transform=transform)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [15743, 3934])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32,\n",
    "                                          shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=32,\n",
    "                                          shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLevel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, capsule_dimension = 8, num_capsules = 10, num_capsule_units = 6 * 6 * 32, routing = False, iterations=3):\n",
    "        super(CapsuleLevel, self).__init__()\n",
    "        self.routing = routing\n",
    "        self.iterations = iterations\n",
    "        self.num_capsules = num_capsules\n",
    "        self.num_capsule_units = num_capsule_units\n",
    "        if routing == True:\n",
    "            self.route_weights = nn.Parameter(torch.randn(num_capsule_units, num_capsules, out_channels, in_channels))\n",
    "        else:\n",
    "            self.capsules = nn.ModuleList(\n",
    "                [nn.Conv2d(in_channels, out_channels, kernel_size=(9, 9), stride=(2, 2), padding=0) for _ in\n",
    "                 range(capsule_dimension)])\n",
    "\n",
    "            \n",
    "    # The squash function\n",
    "    def squash(self, s, dim=-1):\n",
    "        norm = torch.sum(s**2, dim=dim, keepdim=True)\n",
    "        return norm / (1 + norm) * s / (torch.sqrt(norm) + 1e-8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.routing == True:          # Routing by Agreement\n",
    "            batch_size = x.size(0)\n",
    "            \n",
    "            route_weights = torch.stack([self.route_weights] * batch_size, dim = 0) #dim:([1152, 10, 16, 8])\n",
    "            x = torch.stack([x] * self.num_capsules, dim=2).unsqueeze(4) #dim:([128, 1152, 10, 8, 1])\n",
    "            u_hat = torch.matmul(self.route_weights, x)  #dim:([128, 1152, 10, 16, 1])\n",
    "            u_hat = u_hat.squeeze(-1)   #dim([128, 1152, 10, 16])\n",
    "            temp_u_hat = u_hat.detach()\n",
    "            \n",
    "            #b_ij dim:([128, 1152, 10, 1])\n",
    "            b_ij = Variable(torch.zeros(batch_size, self.num_capsule_units, self.num_capsules, 1).cuda()) \n",
    "            for iteration in range(self.iterations):\n",
    "                c_ij = F.softmax(b_ij, dim=1)   # Equation 1 # c_ij dim:([128, 1152, 10, 1])\n",
    "                s_ij = (c_ij * temp_u_hat).sum(dim=1)  # Equation 2 # s_ij dim:([128, 10, 16])\n",
    "                temp_u_hat = temp_u_hat.unsqueeze(3)  # temp_u_hat dim:([128, 1152, 10, 16, 1])\n",
    "                v_j = self.squash(s_ij, dim=2) # Equation 3  # v_j dim:([128, 10, 16])\n",
    "                v_j_i = torch.stack([v_j] * self.num_capsule_units, dim = 1).unsqueeze(-1) # v_j_i dim:([128, 10, 16, 1])\n",
    "                v_j_i = torch.matmul(temp_u_hat, v_j_i).squeeze(3)  \n",
    "                temp_u_hat = temp_u_hat.squeeze(3)\n",
    "                b_ij = b_ij + v_j_i # Equation 4\n",
    "        else:\n",
    "            v_j = [capsule(x).view(x.size(0), -1, 1) for capsule in self.capsules]   \n",
    "            v_j = torch.cat(v_j, dim=-1)\n",
    "            v_j = self.squash(v_j)\n",
    "\n",
    "        return v_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleNetwork(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super(CapsuleNetwork, self).__init__()\n",
    "        self.batch_size = 32\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=(9, 9), stride=(1, 1), padding=0)\n",
    "        self.primaryCaps = CapsuleLevel(in_channels=256, out_channels=32, capsule_dimension=8)\n",
    "        self.digitCaps   = CapsuleLevel(in_channels=8, out_channels=16, num_capsules=2, routing=True)\n",
    "        self.decoder     = nn.Sequential(\n",
    "            nn.Linear(16 * 2, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, y=None):\n",
    "        x = F.relu(self.conv1(x), inplace=True)\n",
    "        x = self.primaryCaps(x)\n",
    "        x = self.digitCaps(x)\n",
    "        classes = (x ** 2).sum(dim=-1) ** 0.5\n",
    "        classes = F.softmax(classes, dim=-1)\n",
    "        if y is None:\n",
    "            # Get most active capsule\n",
    "            _, max_length_indices = classes.max(dim=1)\n",
    "            y = Variable(torch.eye(2)).cuda().index_select(dim=0, index=Variable(max_length_indices.data))\n",
    "        reconstructions = self.decoder((x * y[:, :, None]).view(x.size(0), -1))\n",
    "        return classes, reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LossFunction, self).__init__()\n",
    "        self.reconstruction_loss = nn.MSELoss(size_average=False)\n",
    "\n",
    "    def forward(self, img, target, classes, reconstructions):\n",
    "        fn_1 = F.relu(0.9 - classes, inplace=True) ** 2  # Calculated for correct digit cap\n",
    "        fn_2 = F.relu(classes - 0.1, inplace=True) ** 2  # Calculated for incorrect digit cap\n",
    "        margin_loss = target * fn_1 + 0.5 * (1. - target) * fn_2\n",
    "        margin_loss = margin_loss.sum()\n",
    "        img = img.view(reconstructions.size()[0], -1)\n",
    "        reconstruction_loss = self.reconstruction_loss(reconstructions, img)\n",
    "        return (margin_loss + 0.0005 * reconstruction_loss) / img.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "def train(train_loader, epoch):\n",
    "    global model\n",
    "    model.train()\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    tr_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        batch_size = data.size(0)\n",
    "        labels = target\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        capsule_loss = LossFunction()\n",
    "        labels = torch.LongTensor(labels)\n",
    "        labels = torch.eye(2).index_select(dim=0, index=labels)\n",
    "        labels = Variable(labels).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        classes, reconstructions = model(data, labels)\n",
    "        loss = capsule_loss(data, labels, classes, reconstructions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss += loss.item()\n",
    "        pred = classes.data.max(1, keepdim=True)[1]\n",
    "        if (batch_idx + 1)% 500 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
    "    train_loss.append(tr_loss / len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader):\n",
    "    global model\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        labels = target\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        labels = torch.LongTensor(labels)\n",
    "        labels = torch.eye(10).index_select(dim=0, index=labels)\n",
    "        labels = Variable(labels).cuda()\n",
    "        classes, reconstructions = model(data)\n",
    "        capsule_loss = LossFunction()\n",
    "        loss += capsule_loss(data, labels, classes, reconstructions).item()\n",
    "        pred = classes.data.max(1, keepdim=True)[1]\n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "    test_loss.append(loss)\n",
    "    print('\\nAverage Validation loss: {:.6f}\\n'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 256, 20, 20]          20,992\n",
      "            Conv2d-2             [-1, 32, 6, 6]         663,584\n",
      "            Conv2d-3             [-1, 32, 6, 6]         663,584\n",
      "            Conv2d-4             [-1, 32, 6, 6]         663,584\n",
      "            Conv2d-5             [-1, 32, 6, 6]         663,584\n",
      "            Conv2d-6             [-1, 32, 6, 6]         663,584\n",
      "            Conv2d-7             [-1, 32, 6, 6]         663,584\n",
      "            Conv2d-8             [-1, 32, 6, 6]         663,584\n",
      "            Conv2d-9             [-1, 32, 6, 6]         663,584\n",
      "     CapsuleLevel-10              [-1, 1152, 8]               0\n",
      "     CapsuleLevel-11                [-1, 2, 16]               0\n",
      "           Linear-12                  [-1, 512]          16,896\n",
      "             ReLU-13                  [-1, 512]               0\n",
      "           Linear-14                 [-1, 1024]         525,312\n",
      "             ReLU-15                 [-1, 1024]               0\n",
      "           Linear-16                  [-1, 784]         803,600\n",
      "          Sigmoid-17                  [-1, 784]               0\n",
      "================================================================\n",
      "Total params: 6,675,472\n",
      "Trainable params: 6,675,472\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.96\n",
      "Params size (MB): 25.46\n",
      "Estimated Total Size (MB): 26.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(CapsuleNetwork().cuda(), input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-70c55372337c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#evaluating the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-79caa8768c19>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(data_loader)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcapsule_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLossFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcapsule_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b1625b9683c2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img, target, classes, reconstructions)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfn_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m  \u001b[0;31m# Calculated for correct digit cap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfn_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m  \u001b[0;31m# Calculated for incorrect digit cap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmargin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfn_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfn_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mmargin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmargin_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstructions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "model = CapsuleNetwork()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "n_epochs = 15\n",
    "for epoch in range(n_epochs):\n",
    "    train(train_loader, epoch)  #Training the model\n",
    "    evaluate(val_loader)  #evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
